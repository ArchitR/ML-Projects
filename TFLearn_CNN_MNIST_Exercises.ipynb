{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "66vFu2CFCTlE"
      },
      "cell_type": "markdown",
      "source": [
        "## Quick Introduction to TFLearn - Exercises\n",
        "\n",
        "This will be an implementation for a single record only (single example in the dataset).\n",
        "\n",
        "**Emmanuel Dufourq** (edufourq@gmail.com - www.emmanueldufourq.com)\n",
        "\n",
        "July 2018\n",
        "\n",
        "*Made for the Theoretical Foundations of Data Science 2018 (African Institute for Mathematical Sciences)*\n",
        "\n",
        "Adapted from https://github.com/tflearn/tflearn/blob/master/examples/images/convnet_mnist.py"
      ]
    },
    {
      "metadata": {
        "id": "wwE1smleD8nv"
      },
      "cell_type": "markdown",
      "source": [
        "## TFlearn\n",
        "\n",
        "Documentation: http://tflearn.org\n",
        "\n",
        "TFLearn, similar to Keras, is a high-level wrapper to Tensorflow. We can build neural networks and other types of networks using TFLearn.\n",
        "\n",
        "There are a lot of examples of how to implement networks using TFLearn here: http://tflearn.org/examples/"
      ]
    },
    {
      "metadata": {
        "id": "wWyG6RB5EOL9"
      },
      "cell_type": "markdown",
      "source": [
        "## Check if a GPU has been allocated\n",
        "\n",
        "Remmeber to request for GPU acceleration by clicking on Edit > Notebook Settings > Select GPU as \"hardware accelerator\".\n",
        "\n",
        "The output of the following code should be: Found GPU at: /device:GPU:0"
      ]
    },
    {
      "metadata": {
        "id": "XCSQMJ3eCOSE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "134074c9-96ad-48f1-8398-c7d415a3d132"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X6KD1Q1IE7NZ"
      },
      "cell_type": "markdown",
      "source": [
        "## We will need to install TFLearn as it is not installed on Colab by default."
      ]
    },
    {
      "metadata": {
        "id": "36jhGVCKE6CQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "f3bfa4f7-d61f-4e88-8ee3-3ce560db81f6"
      },
      "cell_type": "code",
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/ec/e9ce1b52e71f6dff3bd944f020cef7140779e783ab27512ea7c7275ddee5/tflearn-0.3.2.tar.gz (98kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.14.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.11.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->tflearn) (0.45.1)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Running setup.py bdist_wheel for tflearn ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/d0/f6/69/0ef3ee395aac2e5d15d89efd29a9a216f3c27767b43b72c006\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rs7yUp2KEupe"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "9zxn0Bw1CU7n"
      },
      "cell_type": "code",
      "source": [
        "import tflearn\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.normalization import local_response_normalization\n",
        "from tflearn.layers.estimator import regression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BGS86RuAEz9u"
      },
      "cell_type": "markdown",
      "source": [
        "## Import the MNIST dataset from TFLearn"
      ]
    },
    {
      "metadata": {
        "id": "XlI-0B5lFJSW"
      },
      "cell_type": "code",
      "source": [
        "import tflearn.datasets.mnist as mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NOWwJfmZFRfm"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the data and specify that we want the classes to be in their one-hot encoded form"
      ]
    },
    {
      "metadata": {
        "id": "fbTuVDUBE0FL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f0df1874-9597-4678-8e25-6be6796779a5"
      },
      "cell_type": "code",
      "source": [
        "X, Y, testX, testY = mnist.load_data(one_hot=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading MNIST...\n",
            "Succesfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting mnist/train-images-idx3-ubyte.gz\n",
            "Downloading MNIST...\n",
            "Succesfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading MNIST...\n",
            "Succesfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading MNIST...\n",
            "Succesfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fjbkp_v-FWlI"
      },
      "cell_type": "markdown",
      "source": [
        "## Task: check the shape of the data"
      ]
    },
    {
      "metadata": {
        "id": "Nd9lA9aUFV4Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6f530df-e48f-4e8b-c8b5-252e1e3263bd"
      },
      "cell_type": "code",
      "source": [
        "None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "metadata": {
        "id": "OwPznt3DFd-j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3d02f77-c455-48d8-e322-1dd92e829de3"
      },
      "cell_type": "code",
      "source": [
        "None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "metadata": {
        "id": "PnNc-5vGFazR"
      },
      "cell_type": "markdown",
      "source": [
        "## Question: have a look at the shape of X.\n",
        "\n",
        "Can we apply a CNN to this as it is right now or do we need to reshape the data? What should the shape of an image be when we are considering a CNN?"
      ]
    },
    {
      "metadata": {
        "id": "S6bJTGmhF2n2"
      },
      "cell_type": "markdown",
      "source": [
        "## Task: have a look at a few Y values are indeed in their one-hot encoded form"
      ]
    },
    {
      "metadata": {
        "id": "UNgcVwuQF2xM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16575f90-98dd-4712-b5c4-514a949817ac"
      },
      "cell_type": "code",
      "source": [
        "Y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "mIUTsxVNGAAH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fbdb854-cf27-432f-e59b-7627d8c7ae6c"
      },
      "cell_type": "code",
      "source": [
        "None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "metadata": {
        "id": "y3mER82VGC9o"
      },
      "cell_type": "markdown",
      "source": [
        "## Reshape the X values such that they are more suitable for a CNN"
      ]
    },
    {
      "metadata": {
        "id": "Krir6UZHFa68"
      },
      "cell_type": "code",
      "source": [
        "X = X.reshape([-1, 28, 28, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AfPif9UWNSeI"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bG3IGpbWGPW_"
      },
      "cell_type": "markdown",
      "source": [
        "## Task: reshape the X test variable such that it is in a suitable shape for a CNN"
      ]
    },
    {
      "metadata": {
        "id": "f-duk1scGPd7"
      },
      "cell_type": "code",
      "source": [
        "testX = testX.reshape([-1, None, None, None])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ueSh4J_UGX07"
      },
      "cell_type": "markdown",
      "source": [
        "## Define a CNN architecture"
      ]
    },
    {
      "metadata": {
        "id": "xC0_-sC8HB-j"
      },
      "cell_type": "markdown",
      "source": [
        "**We can create an input layer as follows: **\n",
        "\n",
        "`network = input_data(shape=[None, 28, 28, 1], name='input')`\n",
        "\n",
        "Here we are telling the package that it should expect a number of images - hence the keyword None - and that the shape of each image is 28x28x1. Here the MNIST dataset consits of 28x28 pixel images and since the data is greyscale the number of channels is set to 1.\n",
        "\n",
        "**For example, we can create a convolutional layer as follows:**\n",
        "\n",
        "`network = conv_2d(network, 32, 3, activation='relu')`\n",
        "\n",
        "Here we are adding a 2D convolutional layer with 32 filters. Each filter is of size 3x3 and we are telling it to use the ReLU activation.\n",
        "\n",
        "**For example, we  can create a max pooling layer as follows:**\n",
        "\n",
        "`network = max_pool_2d(network, 3)`\n",
        "\n",
        "Here we are adding a 2D max pooling layer of which each kernel is of size 3x3.\n",
        "\n",
        "**For example, we  can add a fully conencted layer as follows:**\n",
        "\n",
        "`network = fully_connected(network, 32, activation='tanh')`\n",
        "\n",
        "Here we are adding a fully connected layer of which there are 32 units. We are telling it to use the tanh activation function.\n",
        "\n",
        "**For example, we  can add dropout as follows:**\n",
        "\n",
        "`network = dropout(network, 0.8)`\n",
        "\n",
        "Here we are adding dropout with a keep probability of 0.8\n",
        "\n",
        "In a similar way to Keras needing the user to specify the .compile() function, in TFLearn we must specify something equivalent.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "network = regression(network, optimizer='adam', learning_rate=0.01,\n",
        "                     loss=None, name='target')\n",
        "```\n",
        "\n",
        "Here we are telling it to using the adam optimiser, with a learning rate of 0.01.\n",
        "\n",
        "Task: which loss function should we use? Find a suitable one here: http://tflearn.org/objectives/\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "PEqJjqEIPrWi"
      },
      "cell_type": "markdown",
      "source": [
        "Remember, when you create multiple models, or, re-execute your models you should reset the graph so that they don't get mixed up. One way to do this: `tf.reset_default_graph()`. Add this piece of code below"
      ]
    },
    {
      "metadata": {
        "id": "AtRCENftP6RJ"
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wlIz1SRSRqIi"
      },
      "cell_type": "markdown",
      "source": [
        "## Task:"
      ]
    },
    {
      "metadata": {
        "id": "UYw7hifdGX8U"
      },
      "cell_type": "code",
      "source": [
        "def cnn_model():\n",
        "\n",
        "  # Input layer\n",
        "  network = None\n",
        "\n",
        "  # Convolutional layer\n",
        "  network = None\n",
        "\n",
        "  # Max pooling layer\n",
        "  network = None\n",
        "\n",
        "   # Convolutional layer\n",
        "  network = None\n",
        "\n",
        "  # Max pooling layer\n",
        "  network = None\n",
        "\n",
        "  # Full connected layer\n",
        "  network = None\n",
        "\n",
        "  # Dropout\n",
        "  network = None\n",
        "\n",
        "  # Full connected layer\n",
        "  network = None\n",
        "\n",
        "  network = regression(network, optimizer='adam', learning_rate=0.01,\n",
        "                     loss=None, name='target')\n",
        "\n",
        "  return network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wtVbF9XCJOsO"
      },
      "cell_type": "markdown",
      "source": [
        "## Task: train the model\n",
        "\n",
        "Specify the training data"
      ]
    },
    {
      "metadata": {
        "id": "AVKsWtcnJOzi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9c8f1fd6-ac62-4f93-86e9-99da8af99638"
      },
      "cell_type": "code",
      "source": [
        "network = cnn_model()\n",
        "\n",
        "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
        "\n",
        "# Train the model\n",
        "model.fit({'input': }, {'target': None}, n_epoch=2,\n",
        "           snapshot_step=100, show_metric=True, run_id='convnet_mnist')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 1719  | total loss: \u001b[1m\u001b[32m0.08147\u001b[0m\u001b[0m | time: 9.667s\n",
            "| Adam | epoch: 002 | loss: 0.08147 - acc: 0.9754 -- iter: 54976/55000\n",
            "Training Step: 1720  | total loss: \u001b[1m\u001b[32m0.08211\u001b[0m\u001b[0m | time: 9.677s\n",
            "| Adam | epoch: 002 | loss: 0.08211 - acc: 0.9763 -- iter: 55000/55000\n",
            "--\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k0wUOPh5T2i3"
      },
      "cell_type": "markdown",
      "source": [
        "## Task: predicting on the test data"
      ]
    },
    {
      "metadata": {
        "id": "XcC9RmU5M9qm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1a9d59bf-df36-4819-cc70-bb91822a9b95"
      },
      "cell_type": "code",
      "source": [
        "model.predict(None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.5345529e-12, 2.1529606e-11, 2.3361972e-07, ..., 9.9998868e-01,\n",
              "        6.7699746e-10, 1.0787893e-05],\n",
              "       [9.3582537e-09, 8.5420062e-09, 1.0000000e+00, ..., 1.5954961e-10,\n",
              "        1.6524876e-10, 1.6200001e-14],\n",
              "       [3.7454259e-07, 9.9913388e-01, 8.6052220e-05, ..., 6.9091046e-05,\n",
              "        1.5892298e-04, 3.0028386e-06],\n",
              "       ...,\n",
              "       [2.3469557e-15, 3.5010933e-10, 5.6509662e-12, ..., 9.2003044e-11,\n",
              "        6.2681216e-10, 3.6527897e-06],\n",
              "       [4.8180826e-10, 7.4064666e-10, 1.0247285e-13, ..., 5.6973933e-11,\n",
              "        9.5605265e-06, 3.1222847e-10],\n",
              "       [1.6138503e-05, 2.4989856e-06, 3.7305168e-09, ..., 1.5022507e-13,\n",
              "        1.7038620e-07, 1.3160183e-11]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "metadata": {
        "id": "G-y22mJkT5Mp"
      },
      "cell_type": "markdown",
      "source": [
        "## Predicting in a single example.\n",
        "\n",
        "Try and make sense of the following by breaking down the function into smaller chunks"
      ]
    },
    {
      "metadata": {
        "id": "iaAeKI0OSQhm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42019872-c5db-4781-83c2-c986465f0ae7"
      },
      "cell_type": "code",
      "source": [
        "np.argmax(model.predict(np.reshape(testX[0],(1, 28,28,1))),axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "metadata": {
        "id": "HjYrW_YcVche"
      },
      "cell_type": "markdown",
      "source": [
        "## Predicting on all the test data and convert the output to labels"
      ]
    },
    {
      "metadata": {
        "id": "DzI396U_TKcO"
      },
      "cell_type": "code",
      "source": [
        "predictions_testX = np.argmax(model.predict(np.reshape(testX,(-1, 28,28,1))),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "alKg6dfwVkeV"
      },
      "cell_type": "markdown",
      "source": [
        "## Take a look at the first 5 predictions and the first 5 correct values"
      ]
    },
    {
      "metadata": {
        "id": "ruPsAJMDVgH-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3816e3cc-487f-442d-c84e-a97fde6b8fbd"
      },
      "cell_type": "code",
      "source": [
        "predictions_testX[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "metadata": {
        "id": "A5mVxunBURG6"
      },
      "cell_type": "code",
      "source": [
        "correct_values = np.argmax(testY, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FsOkQiVDVDJJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46a93215-c998-4bf9-c2fe-38f77c31d214"
      },
      "cell_type": "code",
      "source": [
        "correct_values[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "metadata": {
        "id": "PQGYWZtXUgL4"
      },
      "cell_type": "markdown",
      "source": [
        "## Display a confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "7zEFNC7TUgS4"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mG7JNR4DUgl-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d428723e-d8e7-460a-93e3-0db40f6c46f0"
      },
      "cell_type": "code",
      "source": [
        "confusion_matrix(correct_values, predictions_testX)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 972,    0,    3,    1,    0,    0,    2,    1,    1,    0],\n",
              "       [   0, 1121,    3,    0,    3,    0,    1,    6,    1,    0],\n",
              "       [   0,    0, 1014,    3,    0,    0,    1,   13,    1,    0],\n",
              "       [   0,    0,    0,  996,    0,    9,    0,    4,    1,    0],\n",
              "       [   0,    2,    2,    0,  957,    0,    2,    6,    1,   12],\n",
              "       [   2,    0,    0,    2,    0,  882,    1,    1,    2,    2],\n",
              "       [   6,    5,    1,    0,    1,    3,  934,    0,    8,    0],\n",
              "       [   0,    1,    1,    2,    0,    0,    0, 1021,    0,    3],\n",
              "       [   2,    1,    1,    3,    1,    1,    0,    3,  961,    1],\n",
              "       [   0,    0,    0,    1,    5,    3,    0,    4,    5,  991]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "metadata": {
        "id": "XMMswYqbYzSh"
      },
      "cell_type": "markdown",
      "source": [
        "Information about confusion matrix is available here: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ]
    },
    {
      "metadata": {
        "id": "nGQEYQ3XUh5I"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}